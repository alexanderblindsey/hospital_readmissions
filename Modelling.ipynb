{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (RandomizedSearchCV,\n",
    "                                     GridSearchCV)\n",
    "from sklearn.ensemble import (VotingClassifier,\n",
    "                              AdaBoostClassifier,\n",
    "                              RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.linear_model import (LogisticRegression,\n",
    "                                  SGDClassifier)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             f1_score, \n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             roc_auc_score,\n",
    "                             classification_report,\n",
    "                             roc_curve)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/Processed/X_train.csv')\n",
    "X_test = pd.read_csv('Data/Processed/X_test.csv')\n",
    "y_train = pd.read_csv('Data/Processed/y_train.csv', squeeze=True)\n",
    "y_test = pd.read_csv('Data/Processed/y_test.csv', squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Hyperparameter Optimization\n",
    "\n",
    "Several models are trained using `RandomizedSearchCV` and `GridSearchCV`. I use 5-fold cross validation to select the combination of hyperparameters that maximizes accuracy on the out-of-fold prediction. The following models are used:\n",
    "- Ridge Regression\n",
    "- Stochastic Gradient Descent (SGD) Classifier\n",
    "- Random Forest Classifier\n",
    "- Adaboost Classifier using Decision Trees with a depth of 1\n",
    "- Hardvoting Classifier\n",
    "\n",
    "If a hospital were to use a similair model in a production setting, they may optimize for precision or recall depending on the weight they put on false negatives or positives.\n",
    "\n",
    "Logistic regression with lasso regularization was also used, but had trouble converging in a reasonable amount of time (<5 minutes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'accuracy'\n",
    "\n",
    "scores = {} # create empty dict to store models and cross validation best scores\n",
    "\n",
    "def results(estimator_name, estimator):\n",
    "    \"\"\"\n",
    "    1. Adds fitted model name, fitted model.best_estimator_ and .best_score_ from RandomizedSearchCV to \n",
    "    scores, a nested dictionary.\n",
    "    \"\"\"\n",
    "    bp = estimator.best_params_\n",
    "    eb = estimator.best_estimator_\n",
    "    es = estimator.best_score_\n",
    "    \n",
    "    scores[estimator_name] = {}\n",
    "    scores[estimator_name][eb] = es\n",
    "    \n",
    "    return print(f'Best params: {bp} \\n\\nBest score: {es*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'solver': 'sag', 'class_weight': None, 'C': 12} \n",
      "\n",
      "Best score: 63.23451335050974%\n"
     ]
    }
   ],
   "source": [
    "p = {'C':np.arange(1, 16, 1),\n",
    "     'solver':['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "     'class_weight':[None, 'balanced']}\n",
    "ridge = RandomizedSearchCV(LogisticRegression(penalty='l2',\n",
    "                                              max_iter=2000),\n",
    "                           param_distributions=p,\n",
    "                           n_jobs=-1,\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           scoring=metric)\n",
    "ridge.fit(X_train, y_train.ravel())\n",
    "results('ridge', ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'penalty': 'l2', 'loss': 'huber', 'epsilon': 1.2575, 'alpha': 0.5000005} \n",
      "\n",
      "Best score: 62.080952132838775%\n"
     ]
    }
   ],
   "source": [
    "p = {'alpha':np.linspace(0.000001, 1, 5),\n",
    "     'penalty':['l1', 'l2'],\n",
    "     'loss':['hinge', 'log', 'squared_loss', 'huber'],\n",
    "     'epsilon':np.linspace(0.01, 5, 5)}\n",
    "sgd = RandomizedSearchCV(SGDClassifier(),\n",
    "                         param_distributions=p,\n",
    "                         n_jobs=-1,\n",
    "                         cv=5, \n",
    "                         verbose=1,\n",
    "                         scoring=metric)\n",
    "sgd.fit(X_train, y_train)\n",
    "results('SGD', sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   48.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 258, 'min_samples_split': 19, 'min_samples_leaf': 23, 'max_features': 'auto', 'max_depth': 65, 'bootstrap': True} \n",
      "\n",
      "Best score: 63.701185189374%\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "p = {'n_estimators':np.linspace(10, 300, 15).astype(int),\n",
    "     'bootstrap':[True, False],\n",
    "     'max_depth':[None, 50, 55, 58, 60, 62, 65, 67, 70, 72, 75],\n",
    "     'min_samples_split':np.linspace(2, 25, 10).astype(int),\n",
    "     'min_samples_leaf':np.linspace(2, 100, 10).astype(int),\n",
    "     'max_features':['auto', 'log2']}\n",
    "\n",
    "randomforest = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                                  param_distributions=p,\n",
    "                                  n_jobs=-1,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=metric)\n",
    "randomforest.fit(X_train, y_train)\n",
    "results('random forest', randomforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 120, 'learning_rate': 0.6210526315789474} \n",
      "\n",
      "Best score: 63.49668663920085%\n"
     ]
    }
   ],
   "source": [
    "# adaboost with Decision Trees of depth 1\n",
    "p = {'n_estimators':np.arange(20, 150, 2),\n",
    "     'learning_rate':np.linspace(0.1, 1, 20)}\n",
    "\n",
    "adb = RandomizedSearchCV(AdaBoostClassifier(),\n",
    "                         param_distributions=p,\n",
    "                         cv=5,\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1,\n",
    "                         scoring=metric)\n",
    "adb.fit(X_train, y_train)\n",
    "results('adaboost', adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'weights': array([4, 3, 2, 1])} \n",
      "\n",
      "Best score: 63.51067265254595%\n"
     ]
    }
   ],
   "source": [
    "# hardvoting\n",
    "model_scores=[]\n",
    "\n",
    "for c in [randomforest, adb, ridge, sgd]:\n",
    "    model_scores.append(c.best_score_)\n",
    "model_scores = ss.rankdata(model_scores).astype(int)\n",
    "\n",
    "p = {'weights':[None, model_scores]}\n",
    "hardvoting = GridSearchCV(VotingClassifier(estimators=[('randomforestclf', randomforest.best_estimator_),\n",
    "                                                       ('adaboostclf', adb.best_estimator_),\n",
    "                                                       ('ridgeclf', ridge.best_estimator_),\n",
    "                                                       ('sgdclf', sgd.best_estimator_)],\n",
    "                                           voting='hard'),\n",
    "                          param_grid=p,\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          verbose=1,\n",
    "                          scoring=metric)\n",
    "hardvoting.fit(X_train, y_train)\n",
    "results('hardvoting', hardvoting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'weights': array([4, 3, 2, 1])} \n",
      "\n",
      "Best score: 63.51067265254595%\n"
     ]
    }
   ],
   "source": [
    "# softvoting\n",
    "model_scores = []\n",
    "for c in [randomforest, adb, ridge]:\n",
    "    model_scores.append(c.best_score_)\n",
    "model_scores = ss.rankdata(model_scores).astype(int)\n",
    "\n",
    "p = {'weights':[None, model_scores]}\n",
    "softvoting = GridSearchCV(VotingClassifier(estimators=[('randomforestclf', randomforest.best_estimator_),\n",
    "                                                       ('adaboostclf', adb.best_estimator_),\n",
    "                                                       ('ridgeclf', ridge.best_estimator_)],\n",
    "                                           voting='soft'),\n",
    "                          param_grid=p,\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          verbose=1,\n",
    "                          scoring=metric)\n",
    "softvoting.fit(X_train, y_train)\n",
    "results('hardvoting', hardvoting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of Fold Prediction Performance\n",
    "\n",
    "The following is the accuracy of the best out of fold prediction for each estimator. As can be seen below, the out of fold prediction accuracy and test set prediction accuracy in the Results section is very close, indicating that the models are not overfitting. \n",
    "\n",
    "Overfitting would be unlikely considering cross-validation was used with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Results\n",
      "ridge: 63.23451335%\n",
      "SGD: 62.08095213%\n",
      "random forest: 63.70118519%\n",
      "adaboost: 63.49668664%\n",
      "hardvoting: 63.51067265%\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validation Results')\n",
    "for k, v in scores.items():\n",
    "    for k_, v_ in scores[k].items():\n",
    "        print(f'{k}: {v_*100:.8f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Below is the baseline accuracy - a model outputting all 0's would achieve accuracy of 91.31%. \n",
    "\n",
    "The models no variance in readmission and perform as well as a model predicting only 0's (no readmission). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.85738255033557"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = y_test.value_counts()[0]/(y_test.value_counts()[1] + y_test.value_counts()[0]) * 100\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in scores.items():\n",
    "    for k_, v_ in scores[k].items():\n",
    "        accuracy = accuracy_score(y_true=y_test,\n",
    "                                  y_pred=k_.predict(X_test))*100\n",
    "        report = classification_report(y_true=y_test,\n",
    "                                       y_pred=k_.predict(X_test),\n",
    "                                       zero_division=0)\n",
    "        print(f'Model: {k} \\nAccuracy: {accuracy:.8f}% \\n{report}')\n",
    "        if accuracy > baseline_accuracy:\n",
    "            print(f'Better than baseline.\\nAbove baseline: {(accuracy-baseline_accuracy)}.\\n\\n')\n",
    "        else:\n",
    "            print(f'Worse than baseline.\\nBelow baseline: {(baseline_accuracy-accuracy)}.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below ROC scores also paint a grim picture - the dotted line represents a totally random model, and so curves farther away from the model are better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(mod, attribute, X_test=X_test, y_test=y_test):\n",
    "    \"\"\"\n",
    "    Disclaimer: This function is an adaptation from code written by Paul Schrimpf, Thomas Sargent, \n",
    "    Quentin Batista, and Natasha Watkins, taken from datascience.quantecon.org. \n",
    "    \"\"\"\n",
    "    # predicted_probs is an N x 2 array, where N is number of observations\n",
    "    # and 2 is number of classes\n",
    "    predicted_probs = mod.predict_proba(X_test)\n",
    "\n",
    "    # keep the second column, for label=1\n",
    "    predicted_prob1 = predicted_probs[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, predicted_prob1)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.plot([0, 1], [0, 1], \"k--\")\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set_xlabel(\"False Positive Rate\", size=12)\n",
    "    ax.set_ylabel(\"True Positive Rate\", size=12)\n",
    "    ax.set_title(f\"ROC Curve - {attribute}\", size=15)\n",
    "\n",
    "for k, v in scores.items():\n",
    "    for k_, v_ in scores[k].items():\n",
    "        if k=='SGD' or k=='hardvoting': # probability methods not available for huber loss function or \n",
    "            continue                    # for hardvoting classifier\n",
    "        else:\n",
    "            plot_roc(mod=k_, attribute=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The models do not do particularly well in predicting...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
